"""
Notion æ•°æ®ç†µå¢æ£€æµ‹ä¸»è„šæœ¬
å®šæœŸæ£€æµ‹ Notion å·¥ä½œåŒºä¸­çš„æ•°æ®ç†µå¢æƒ…å†µï¼ŒåŒ…æ‹¬æ—¶é—´è¡°å‡ç†µå’Œé“¾æ¥æ–­è£‚ç‡
"""

import os
import sys
from typing import List, Optional
from dotenv import load_dotenv

# è®¾ç½®è¾“å‡ºç¼–ç ä¸º UTF-8ï¼ˆWindows å…¼å®¹ï¼‰
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

from notion_api_client import NotionClient
from data_collector import DataCollector
from entropy_calculator import EntropyCalculator
from report_generator import ReportGenerator


def format_notion_id(id_str: str) -> str:
    """
    æ ¼å¼åŒ– Notion IDï¼ˆæ·»åŠ è¿å­—ç¬¦ï¼‰
    Notion ID æ ¼å¼ï¼š8-4-4-4-12 (32ä½åå…­è¿›åˆ¶)
    
    Args:
        id_str: åŸå§‹ ID å­—ç¬¦ä¸²ï¼ˆå¯èƒ½æ²¡æœ‰è¿å­—ç¬¦ï¼‰
        
    Returns:
        æ ¼å¼åŒ–åçš„ IDï¼ˆå¸¦è¿å­—ç¬¦ï¼‰
    """
    # ç§»é™¤æ‰€æœ‰è¿å­—ç¬¦å’Œç©ºæ ¼
    clean_id = id_str.replace('-', '').replace(' ', '')
    
    # å¦‚æœä¸æ˜¯32ä½ï¼Œç›´æ¥è¿”å›ï¼ˆå¯èƒ½æ˜¯æ— æ•ˆIDï¼‰
    if len(clean_id) != 32:
        return id_str
    
    # æ ¼å¼åŒ–ä¸º 8-4-4-4-12
    return f"{clean_id[0:8]}-{clean_id[8:12]}-{clean_id[12:16]}-{clean_id[16:20]}-{clean_id[20:32]}"


def parse_database_ids(env_value: Optional[str]) -> Optional[List[str]]:
    """
    è§£æç¯å¢ƒå˜é‡ä¸­çš„æ•°æ®åº“IDåˆ—è¡¨
    
    Args:
        env_value: ç¯å¢ƒå˜é‡å€¼ï¼Œå¤šä¸ªIDç”¨é€—å·åˆ†éš”
        
    Returns:
        æ•°æ®åº“IDåˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneæˆ–ç©ºåˆ™è¿”å›None
    """
    if not env_value or not env_value.strip():
        return None
    
    ids = [id.strip() for id in env_value.split(',') if id.strip()]
    # æ ¼å¼åŒ–æ‰€æœ‰ IDï¼ˆæ·»åŠ è¿å­—ç¬¦ï¼‰
    formatted_ids = [format_notion_id(id) for id in ids]
    return formatted_ids if formatted_ids else None


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("Notion æ•°æ®ç†µå¢æ£€æµ‹å·¥å…·")
    print("=" * 60)
    print()
    
    # è¯»å–é…ç½®
    notion_token = os.getenv('NOTION_TOKEN')
    if not notion_token:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° NOTION_TOKEN ç¯å¢ƒå˜é‡")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® NOTION_TOKEN")
        sys.exit(1)
    
    database_ids = parse_database_ids(os.getenv('DATABASE_IDS'))
    threshold_days = int(os.getenv('TIME_DECAY_THRESHOLD_DAYS', '30'))
    warning_threshold = float(os.getenv('TIME_DECAY_WARNING_THRESHOLD', '40.0'))
    
    print(f"é…ç½®ä¿¡æ¯:")
    print(f"  - æ—¶é—´è¡°å‡é˜ˆå€¼: {threshold_days} å¤©")
    print(f"  - è­¦å‘Šé˜ˆå€¼: {warning_threshold}%")
    if database_ids:
        print(f"  - æŒ‡å®šæ•°æ®åº“æ•°é‡: {len(database_ids)}")
    else:
        print(f"  - ç›‘æ§èŒƒå›´: æ‰€æœ‰å¯è®¿é—®çš„æ•°æ®åº“")
    print()
    
    try:
        # åˆå§‹åŒ–ç»„ä»¶
        print("ğŸ”Œ æ­£åœ¨è¿æ¥ Notion API...")
        notion_client = NotionClient(token=notion_token)
        data_collector = DataCollector(notion_client)
        entropy_calculator = EntropyCalculator(notion_client)
        report_generator = ReportGenerator()
        print("âœ… è¿æ¥æˆåŠŸ")
        print()
        
        # æ”¶é›†æ•°æ®
        print("ğŸ“Š æ­£åœ¨æ”¶é›†æ•°æ®...")
        database_pages = data_collector.collect_database_data(database_ids)
        
        if not database_pages:
            print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•æ•°æ®åº“æˆ–æ— æ³•è®¿é—®")
            print()
            print("å¯èƒ½çš„åŸå› ï¼š")
            print("1. æŒ‡å®šçš„æ•°æ®åº“ ID ä¸æ­£ç¡®æˆ–æœªæˆæƒç»™é›†æˆ")
            print("2. é›†æˆæ²¡æœ‰è®¿é—®è¿™äº›æ•°æ®åº“çš„æƒé™")
            print()
            print("å»ºè®®ï¼š")
            print("- åœ¨ .env æ–‡ä»¶ä¸­æ¸…ç©º DATABASE_IDSï¼ˆç•™ç©ºæˆ–åˆ é™¤è¯¥è¡Œï¼‰")
            print("- è®©è„šæœ¬è‡ªåŠ¨æœç´¢æ‰€æœ‰å¯è®¿é—®çš„æ•°æ®åº“")
            print("- æˆ–è€…åœ¨ Notion ä¸­å°†æ•°æ®åº“æˆæƒç»™é›†æˆ")
            sys.exit(0)
        
        print(f"âœ… æ‰¾åˆ° {len(database_pages)} ä¸ªæ•°æ®åº“")
        print()
        
        # è®¡ç®—ç†µæŒ‡æ ‡
        print("ğŸ§® æ­£åœ¨è®¡ç®—ç†µæŒ‡æ ‡...")
        database_results = {}
        all_pages = []
        
        for db_id, pages in database_pages.items():
            print(f"  å¤„ç†æ•°æ®åº“: {db_id[:8]}... ({len(pages)} ä¸ªé¡µé¢)")
            all_pages.extend(pages)
            
            # è·å–æ•°æ®åº“ä¿¡æ¯
            db_info = data_collector.get_database_info(db_id)
            
            # è®¡ç®—å¤šæ—¶é—´çª—å£è¡°å‡
            multi_decay = entropy_calculator.calculate_multi_threshold_decay(
                pages, thresholds=[30, 90, 150, 300]
            )
            
            # è®¡ç®—é“¾æ¥æ–­è£‚ç‡
            link_breakage_rate, isolated_pages, link_stats = entropy_calculator.calculate_link_breakage_rate(
                pages
            )
            
            database_results[db_id] = {
                'database_info': db_info,
                'pages_count': len(pages),
                'multi_threshold_decay': multi_decay,
                'link_breakage_rate': link_breakage_rate,
                'isolated_pages': isolated_pages,
                'link_stats': link_stats
            }
        
        print()
        
        # è®¡ç®—æ•´ä½“æŒ‡æ ‡
        print("ğŸ“ˆ æ­£åœ¨è®¡ç®—æ•´ä½“æŒ‡æ ‡...")
        
        # è®¡ç®—å¤šæ—¶é—´çª—å£è¡°å‡
        print("  è®¡ç®—å¤šæ—¶é—´çª—å£è¡°å‡...")
        overall_multi_decay = entropy_calculator.calculate_multi_threshold_decay(
            all_pages, thresholds=[30, 90, 150, 300]
        )
        overall_time_decay_entropy = overall_multi_decay['thresholds'].get(30, {}).get('rate', 0)
        
        overall_link_breakage_rate, _, overall_link_stats = entropy_calculator.calculate_link_breakage_rate(
            all_pages
        )
        
        # è®¡ç®—æ–°å¢æŒ‡æ ‡
        print("  è®¡ç®—æ´»è·ƒåº¦æŒ‡æ ‡...")
        activity_metrics = entropy_calculator.calculate_activity_metrics(all_pages)
        
        print("  è®¡ç®—å±æ€§å®Œæ•´åº¦...")
        property_metrics = entropy_calculator.calculate_property_completeness(all_pages)
        
        print("  è®¡ç®—åˆ†ç±»è¦†ç›–ç‡...")
        categorization_metrics = entropy_calculator.calculate_categorization_coverage(all_pages)
        
        print("  æŠ½æ ·æ£€æµ‹è¿æ¥å¯†åº¦...")
        mention_metrics = entropy_calculator.calculate_mention_density(all_pages, sample_rate=0.1)
        
        # è®¡ç®—å¥åº·åº¦è¯„åˆ†
        health_score = entropy_calculator.calculate_health_score(
            time_decay_entropy=overall_time_decay_entropy,
            activity_rate_30d=activity_metrics['activity_rate_30d'],
            property_completeness=property_metrics['avg_completeness'],
            categorization_coverage=categorization_metrics['coverage_rate']
        )
        
        print()
        print("âœ… æ—¶é—´è¡°å‡ç†µï¼ˆå¤šçª—å£ï¼‰:")
        for t in [30, 90, 150, 300]:
            decay_data = overall_multi_decay['thresholds'].get(t, {})
            print(f"   >{t}å¤©: {decay_data.get('rate', 0):.1f}% ({decay_data.get('count', 0)}ä¸ªé¡µé¢)")
        print(f"âœ… 30å¤©æ´»è·ƒç‡: {activity_metrics['activity_rate_30d']:.2f}%")
        print(f"âœ… å±æ€§å®Œæ•´åº¦: {property_metrics['avg_completeness']:.2f}%")
        print(f"âœ… åˆ†ç±»è¦†ç›–ç‡: {categorization_metrics['coverage_rate']:.2f}%")
        print(f"âœ… è¿æ¥å¯†åº¦(æŠ½æ ·): {mention_metrics['mention_density']:.2f}%")
        if overall_link_breakage_rate < 0:
            print(f"â„¹ï¸  é“¾æ¥æ–­è£‚ç‡: æ— æ³•è®¡ç®—ï¼ˆæ•°æ®åº“æœªä½¿ç”¨å…³è”åŠŸèƒ½ï¼‰")
        else:
            print(f"âœ… æ•´ä½“é“¾æ¥æ–­è£‚ç‡: {overall_link_breakage_rate:.2f}%")
        print(f"ğŸ¥ çŸ¥è¯†åº“å¥åº·åº¦: {health_score['score']:.1f}åˆ† ({health_score['grade']} - {health_score['status']})")
        print()
        
        # ç”ŸæˆæŠ¥å‘Š
        print("ğŸ“ æ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
        report_content = report_generator.generate_report(
            database_results=database_results,
            overall_time_decay_entropy=overall_time_decay_entropy,
            overall_link_breakage_rate=overall_link_breakage_rate,
            threshold_days=threshold_days,
            warning_threshold=warning_threshold,
            activity_metrics=activity_metrics,
            property_metrics=property_metrics,
            categorization_metrics=categorization_metrics,
            mention_metrics=mention_metrics,
            health_score=health_score,
            multi_threshold_decay=overall_multi_decay
        )
        
        # ä¿å­˜æŠ¥å‘Šåˆ° report ç›®å½•
        report_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'report')
        os.makedirs(report_dir, exist_ok=True)
        report_path = report_generator.save_report(report_content, output_dir=report_dir)
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        print()
        
        # æ˜¾ç¤ºæ‘˜è¦
        print("=" * 60)
        print("æ£€æµ‹å®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ¥ çŸ¥è¯†åº“å¥åº·åº¦: {health_score['score']:.1f}åˆ† ({health_score['grade']} - {health_score['status']})")
        print(f"ğŸ“Š æ—¶é—´è¡°å‡ç†µ: {overall_time_decay_entropy:.2f}%")
        print(f"ğŸ“ˆ 30å¤©æ´»è·ƒç‡: {activity_metrics['activity_rate_30d']:.2f}%")
        print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {report_path}")
        print()
        
        # å¦‚æœæœ‰è­¦å‘Šï¼Œæ˜¾ç¤ºæé†’
        if overall_time_decay_entropy > warning_threshold:
            print(f"âš ï¸  è­¦å‘Š: æ—¶é—´è¡°å‡ç†µè¶…è¿‡é˜ˆå€¼ ({warning_threshold}%)")
            print("   å»ºè®®åŠæ—¶æ¸…ç†è¿‡æœŸå†…å®¹")
        
        if overall_link_breakage_rate > 30:
            print(f"âš ï¸  è­¦å‘Š: é“¾æ¥æ–­è£‚ç‡è¾ƒé«˜ ({overall_link_breakage_rate:.2f}%)")
            print("   å»ºè®®å¢å¼ºçŸ¥è¯†ç½‘ç»œè¿æ¥")
        elif overall_link_breakage_rate < 0:
            print(f"â„¹ï¸  æç¤º: æ•°æ®åº“æœªä½¿ç”¨ relationï¼ˆå…³è”ï¼‰å±æ€§")
            print("   é“¾æ¥æ–­è£‚ç‡æŒ‡æ ‡éœ€è¦æ•°æ®åº“é…ç½®å…³è”å­—æ®µæ‰èƒ½è®¡ç®—")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()

